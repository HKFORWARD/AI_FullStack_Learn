{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyM/HivhX4eebLUo/vt/hroh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"61457b7dbeba4083b5028a283fda2f77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c93c0395638b4d0d99b535ce60c6df21","IPY_MODEL_31141f27b0d241ea8cfbac97a457a5d9","IPY_MODEL_b0757b4804ad4f01b84cced7696f48b1"],"layout":"IPY_MODEL_5950e8e0a3894f13acf289cbb3d6c29e"}},"c93c0395638b4d0d99b535ce60c6df21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a9119ea481f4c2ebd6fa2e84299265f","placeholder":"​","style":"IPY_MODEL_b48d8604b74d4302bcc1342cd27b094d","value":"model.safetensors: 100%"}},"31141f27b0d241ea8cfbac97a457a5d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcd0f3a7d5834880aca5152e0dfb068d","max":1805551084,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3615396e2ff943a48fcc1c1847f88a09","value":1805551084}},"b0757b4804ad4f01b84cced7696f48b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5b3d7dd647647c0849f3fc45deb2073","placeholder":"​","style":"IPY_MODEL_3612ff9fbaeb4c9488157d01f1040019","value":" 1.81G/1.81G [00:08&lt;00:00, 935MB/s]"}},"5950e8e0a3894f13acf289cbb3d6c29e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a9119ea481f4c2ebd6fa2e84299265f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b48d8604b74d4302bcc1342cd27b094d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcd0f3a7d5834880aca5152e0dfb068d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3615396e2ff943a48fcc1c1847f88a09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5b3d7dd647647c0849f3fc45deb2073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3612ff9fbaeb4c9488157d01f1040019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b30827fc4fe94b0b8051e97c2e49d19b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7c0754b99c34bf0a5ff02423fd9191f","IPY_MODEL_a06ee37d994a4475aec90ad106ae82e1","IPY_MODEL_00695dcaac1843a4ac6094992038fbd0"],"layout":"IPY_MODEL_4a4b4ddbce2643fb9eae2dde5098df57"}},"d7c0754b99c34bf0a5ff02423fd9191f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0975a098b24b48b8bdecebb6534a61e8","placeholder":"​","style":"IPY_MODEL_503a2a0815bd4db38b7c6342989afd12","value":"generation_config.json: 100%"}},"a06ee37d994a4475aec90ad106ae82e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3d14df741845febced56c271dd30c0","max":236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba76767cc2364f9ea9d35511dfb791cf","value":236}},"00695dcaac1843a4ac6094992038fbd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee9618ee5c804af59f3a51758fb2ffa0","placeholder":"​","style":"IPY_MODEL_7172d1eaa1af4d70ac6f9cd3594d04e6","value":" 236/236 [00:00&lt;00:00, 27.8kB/s]"}},"4a4b4ddbce2643fb9eae2dde5098df57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0975a098b24b48b8bdecebb6534a61e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"503a2a0815bd4db38b7c6342989afd12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd3d14df741845febced56c271dd30c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba76767cc2364f9ea9d35511dfb791cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee9618ee5c804af59f3a51758fb2ffa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7172d1eaa1af4d70ac6f9cd3594d04e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"420209a6c71e4640876e159efca8f313":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69e9118867df4971b18e7deff9cb0d2b","IPY_MODEL_cb45382a7c574c00a505f8d19972f4a5","IPY_MODEL_641e40b82547425e8ead3898f0433751"],"layout":"IPY_MODEL_273c3744058542838f15fef3d1bbd64f"}},"69e9118867df4971b18e7deff9cb0d2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e0fb6b1f0a24588afab96abf23a7afe","placeholder":"​","style":"IPY_MODEL_c8746adc5c0246439d1ce9af112d2fd0","value":"tokenizer_config.json: "}},"cb45382a7c574c00a505f8d19972f4a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28d491f6976e4047ad204fcffa851378","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08d73708977b46c793f67e17d8ba252d","value":1}},"641e40b82547425e8ead3898f0433751":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a5b1bc85f4c45bd9a322f6c1379adaf","placeholder":"​","style":"IPY_MODEL_7c8c8dbac0c64c5cb3ff252ace2329a7","value":" 6.78k/? [00:00&lt;00:00, 821kB/s]"}},"273c3744058542838f15fef3d1bbd64f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e0fb6b1f0a24588afab96abf23a7afe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8746adc5c0246439d1ce9af112d2fd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28d491f6976e4047ad204fcffa851378":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"08d73708977b46c793f67e17d8ba252d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a5b1bc85f4c45bd9a322f6c1379adaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c8c8dbac0c64c5cb3ff252ace2329a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2a1f84c0a7447bac8626fbb3f39a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8cc7383de124479e851c6096958951ac","IPY_MODEL_e0293b229d37498e9b5f777f140b115a","IPY_MODEL_b4d6f4254a5041ffa517ec0c80857a3e"],"layout":"IPY_MODEL_d7ae72a271fe49028f988e3d7608e95d"}},"8cc7383de124479e851c6096958951ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df7a02efb0204c0a89a189365569327b","placeholder":"​","style":"IPY_MODEL_d55950dc82f74571b88fad328bb35d80","value":"tokenizer.json: 100%"}},"e0293b229d37498e9b5f777f140b115a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b6629a62014557944ea81e1952bebc","max":11422778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f45543c7aa91460ea17c2b80854207d2","value":11422778}},"b4d6f4254a5041ffa517ec0c80857a3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b2bdead0f2f44cc8b84ab8394bdc693","placeholder":"​","style":"IPY_MODEL_00e970ee94484549a518128f39070125","value":" 11.4M/11.4M [00:00&lt;00:00, 67.7kB/s]"}},"d7ae72a271fe49028f988e3d7608e95d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df7a02efb0204c0a89a189365569327b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55950dc82f74571b88fad328bb35d80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4b6629a62014557944ea81e1952bebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45543c7aa91460ea17c2b80854207d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b2bdead0f2f44cc8b84ab8394bdc693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e970ee94484549a518128f39070125":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b897916e6f504460b0f7b57d79b95344":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27fc571f3467433a928dc82bbd4a5d44","IPY_MODEL_2d47a0cba0754496b94d921004e3bade","IPY_MODEL_855c21fb9784413daebe9894e028affc"],"layout":"IPY_MODEL_b860f806426443629c9db1ab127cf796"}},"27fc571f3467433a928dc82bbd4a5d44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_befd05dcbf7c44d49baf0be3829df511","placeholder":"​","style":"IPY_MODEL_5b1f2c957a8649ef954962eae65ecdf2","value":"special_tokens_map.json: 100%"}},"2d47a0cba0754496b94d921004e3bade":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_acd7f7e2849d4d38b188054552feeee4","max":472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa8bdf232c874ea49d491c4be0b8bb23","value":472}},"855c21fb9784413daebe9894e028affc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_676b3dfb2b2a486aba1eff95ab1c7536","placeholder":"​","style":"IPY_MODEL_5c76424449d4443da3dec203cab9a577","value":" 472/472 [00:00&lt;00:00, 60.2kB/s]"}},"b860f806426443629c9db1ab127cf796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"befd05dcbf7c44d49baf0be3829df511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1f2c957a8649ef954962eae65ecdf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acd7f7e2849d4d38b188054552feeee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa8bdf232c874ea49d491c4be0b8bb23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"676b3dfb2b2a486aba1eff95ab1c7536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c76424449d4443da3dec203cab9a577":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a1c55160ea9442e980947c3da07e715":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36bc7625e00940fc806a0668683db47d","IPY_MODEL_ded01950cac94f068642b397c630290f","IPY_MODEL_18fb2efe53df47d48564e83b52ec3822"],"layout":"IPY_MODEL_2a8bdde76bd54a3d83e099970be357bd"}},"36bc7625e00940fc806a0668683db47d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd8d1b66da2b445db147f6e0ac87fba4","placeholder":"​","style":"IPY_MODEL_98aff273647e4e889fe888c425da93a1","value":"README.md: "}},"ded01950cac94f068642b397c630290f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2453867b134d480a8df46d028299ce7c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf7897a39a4345f18170606418548bb4","value":1}},"18fb2efe53df47d48564e83b52ec3822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82490cce89754262956b66dc9b570855","placeholder":"​","style":"IPY_MODEL_3d18fa835f9143ac8d860ecca1a2a0b7","value":" 1.97k/? [00:00&lt;00:00, 216kB/s]"}},"2a8bdde76bd54a3d83e099970be357bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd8d1b66da2b445db147f6e0ac87fba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98aff273647e4e889fe888c425da93a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2453867b134d480a8df46d028299ce7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cf7897a39a4345f18170606418548bb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82490cce89754262956b66dc9b570855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d18fa835f9143ac8d860ecca1a2a0b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b90e1d9ce8646c4b84182d1e6e287b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f061485042e44e8cacd9386d1eb51ca4","IPY_MODEL_1b09dbfb32fb47f085f3366e89b17fea","IPY_MODEL_7507d959839f458da755338750326d3f"],"layout":"IPY_MODEL_ef4e0da22f0f4f5abf3a0c0e37e0cffa"}},"f061485042e44e8cacd9386d1eb51ca4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea405c52f991417e901dad4859bc3de0","placeholder":"​","style":"IPY_MODEL_36cfe0a881644c8b9b3bc4bc33c86f79","value":"medical_o1_sft_Chinese.json: 100%"}},"1b09dbfb32fb47f085f3366e89b17fea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceda78d656d24541a4e9222f55f243fa","max":50634791,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a2f3ef847da459aa2f8a9a25b30059c","value":50634791}},"7507d959839f458da755338750326d3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f35c2e41dd946db943eb007da7d7417","placeholder":"​","style":"IPY_MODEL_7e0c7db8b5de44a9957c382fa2966340","value":" 50.6M/50.6M [00:00&lt;00:00, 192MB/s]"}},"ef4e0da22f0f4f5abf3a0c0e37e0cffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea405c52f991417e901dad4859bc3de0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36cfe0a881644c8b9b3bc4bc33c86f79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceda78d656d24541a4e9222f55f243fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a2f3ef847da459aa2f8a9a25b30059c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f35c2e41dd946db943eb007da7d7417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0c7db8b5de44a9957c382fa2966340":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec99310a8eef4b158bcfa3bd80915cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bbb5f4736c54172ab01fa3e33c0d0dd","IPY_MODEL_09773533f9e84b10867e08297106741a","IPY_MODEL_06cc2c9fde74436896854b3d38db85d8"],"layout":"IPY_MODEL_bba3b4da9a6f48daa8954365af8ada0b"}},"2bbb5f4736c54172ab01fa3e33c0d0dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4b84a0847984f7aa9eb786e4b2d399c","placeholder":"​","style":"IPY_MODEL_2732ff12713e491d8d563a764a8821c9","value":"Generating train split: 100%"}},"09773533f9e84b10867e08297106741a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_386215cc3f554d01b84bd8927349d0cc","max":20171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04a216a1c0a145f888f9327649d7bd4a","value":20171}},"06cc2c9fde74436896854b3d38db85d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff6d5b619fd4e878641d5ac1ca6268a","placeholder":"​","style":"IPY_MODEL_0d2e3b1a994a4233b930ae60fc34f3c1","value":" 20171/20171 [00:00&lt;00:00, 29745.87 examples/s]"}},"bba3b4da9a6f48daa8954365af8ada0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4b84a0847984f7aa9eb786e4b2d399c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2732ff12713e491d8d563a764a8821c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"386215cc3f554d01b84bd8927349d0cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a216a1c0a145f888f9327649d7bd4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ff6d5b619fd4e878641d5ac1ca6268a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d2e3b1a994a4233b930ae60fc34f3c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f489d4959fa54c1dbf48e4423cc16bce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c27f562d447848e388bf20819229f40d","IPY_MODEL_769ddbfc8cc94a12b1f08aabfd0f76a3","IPY_MODEL_3a053679eeb749318b55342f0423d710"],"layout":"IPY_MODEL_424b0013c85649f1869a26b745679293"}},"c27f562d447848e388bf20819229f40d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c8ddf34a9f4fa39434065133d6e563","placeholder":"​","style":"IPY_MODEL_92fa2d23bc26434092275935cba0c700","value":"Map: 100%"}},"769ddbfc8cc94a12b1f08aabfd0f76a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b14857654c43798da82c9f43d4662b","max":20171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce2c77c62a794cdfb383ec6bad8cbced","value":20171}},"3a053679eeb749318b55342f0423d710":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cd42715f3fa4ab68a611a5309501147","placeholder":"​","style":"IPY_MODEL_cca96914c1cd4d0d87dad236db99a53d","value":" 20171/20171 [00:00&lt;00:00, 38244.17 examples/s]"}},"424b0013c85649f1869a26b745679293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67c8ddf34a9f4fa39434065133d6e563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92fa2d23bc26434092275935cba0c700":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8b14857654c43798da82c9f43d4662b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce2c77c62a794cdfb383ec6bad8cbced":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cd42715f3fa4ab68a611a5309501147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cca96914c1cd4d0d87dad236db99a53d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5111a27b342d48acbd2a86652ec6b537":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bbe6c809ec041f797f7da7328af2e47","IPY_MODEL_1b9c320f787a4ff89f9809065555f256","IPY_MODEL_8ee6457daa9e4c98b2968c2391ba6a6e"],"layout":"IPY_MODEL_0027695c4a1447469edea33f5e74e227"}},"5bbe6c809ec041f797f7da7328af2e47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a9db902820b4b3d9f6497f9c9d19236","placeholder":"​","style":"IPY_MODEL_9160ac02519d42ff979fdabd00a61e09","value":"Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"}},"1b9c320f787a4ff89f9809065555f256":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdae64e48c534bc392a39090192f615f","max":20171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1e5e8407c1f41f3946726ff3a381a32","value":20171}},"8ee6457daa9e4c98b2968c2391ba6a6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e7eb67c2e504ab196b8f65b6ffebdb4","placeholder":"​","style":"IPY_MODEL_0d9aa87a936447999b02f25ce17847f6","value":" 20171/20171 [00:18&lt;00:00, 1372.54 examples/s]"}},"0027695c4a1447469edea33f5e74e227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a9db902820b4b3d9f6497f9c9d19236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9160ac02519d42ff979fdabd00a61e09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdae64e48c534bc392a39090192f615f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e5e8407c1f41f3946726ff3a381a32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e7eb67c2e504ab196b8f65b6ffebdb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d9aa87a936447999b02f25ce17847f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 使用 Unsloth 对 DeepSeek-R1-Distill-Qwen-1.5B 模型进行 LoRA 微调\n","\n","本 Notebook 展示了如何使用 `unsloth` 库对 `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B` 模型进行高效的 QLoRA (Low-Rank Adaptation) 微调。\n","\n","整个流程包括：\n","1.  环境准备与库导入\n","2.  加载预训练模型和分词器 (Tokenizer)。\n","3.  在微调前，对模型进行简单的推理测试。\n","4.  下载和格式化训练数据集\n","5.  使用 `unsloth` 的 `FastLanguageModel` 来为模型添加 LoRA 适配器。\n","6.  配置 `SFTTrainer` 监督微调训练配置。\n","7.  启动训练，并观察 Loss 变化情况\n","8.  保存微调后的模型\n","9.  测试训练后的生成结果"],"metadata":{"id":"H3b8XVjXBhBH"}},{"cell_type":"markdown","source":["### 1. 环境准备与库导入\n","\n","首先，我们需要安装并导入所有必要的库。`transformers` 用于加载模型和分词器，`unsloth` 用于高效微调，`trl` 提供了 `SFTTrainer`，而 `datasets` 用于处理数据。\n","\n","**注意**: 在运行此 Notebook 之前，请确保已安装所有依赖包："],"metadata":{"id":"ZcEfzCybBpey"}},{"cell_type":"code","source":["pip install -r requirements-colab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xf_jgZWxFrUA","executionInfo":{"status":"ok","timestamp":1758058033400,"user_tz":-120,"elapsed":26691,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"7381747e-1d21-464c-efeb-bc5d01f8007d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==3.6.0 (from -r requirements-colab.txt (line 1))\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements-colab.txt (line 2)) (2.2.2)\n","Collecting peft==0.17.0 (from -r requirements-colab.txt (line 3))\n","  Downloading peft-0.17.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: timm==1.0.19 in /usr/local/lib/python3.12/dist-packages (from -r requirements-colab.txt (line 4)) (1.0.19)\n","Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-colab.txt (line 5)) (2.8.0+cu126)\n","Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-colab.txt (line 6)) (0.23.0+cu126)\n","Collecting transformers==4.55.2 (from -r requirements-colab.txt (line 7))\n","  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trl==0.21.0 (from -r requirements-colab.txt (line 8))\n","  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n","Collecting unsloth==2025.8.5 (from -r requirements-colab.txt (line 9))\n","  Downloading unsloth-2025.8.5-py3-none-any.whl.metadata (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth_zoo==2025.8.4 (from -r requirements-colab.txt (line 10))\n","  Downloading unsloth_zoo-2025.8.4-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (3.19.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (0.34.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements-colab.txt (line 1)) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements-colab.txt (line 2)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements-colab.txt (line 2)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements-colab.txt (line 2)) (2025.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.17.0->-r requirements-colab.txt (line 3)) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.17.0->-r requirements-colab.txt (line 3)) (1.10.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.17.0->-r requirements-colab.txt (line 3)) (0.6.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements-colab.txt (line 5)) (3.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0->-r requirements-colab.txt (line 6)) (11.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.55.2->-r requirements-colab.txt (line 7)) (2024.11.6)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.55.2->-r requirements-colab.txt (line 7))\n","  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting xformers>=0.0.27.post2 (from unsloth==2025.8.5->-r requirements-colab.txt (line 9))\n","  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n","Collecting bitsandbytes (from unsloth==2025.8.5->-r requirements-colab.txt (line 9))\n","  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n","Collecting tyro (from unsloth==2025.8.5->-r requirements-colab.txt (line 9))\n","  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.2.1)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.45.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (5.29.5)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.1.9)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.35.1)\n","Collecting cut_cross_entropy (from unsloth_zoo==2025.8.4->-r requirements-colab.txt (line 10))\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting msgspec (from unsloth_zoo==2025.8.4->-r requirements-colab.txt (line 10))\n","  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (3.12.15)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (1.1.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements-colab.txt (line 2)) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements-colab.txt (line 1)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements-colab.txt (line 1)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements-colab.txt (line 1)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements-colab.txt (line 1)) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->-r requirements-colab.txt (line 5)) (1.3.0)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (8.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->-r requirements-colab.txt (line 5)) (3.0.2)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.17.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9))\n","  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (4.4.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements-colab.txt (line 1)) (1.20.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (2.19.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements-colab.txt (line 9)) (0.1.2)\n","Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.17.0-py3-none-any.whl (503 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.9/503.9 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth-2025.8.5-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.6/307.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.8.4-py3-none-any.whl (181 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.9/181.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n","Installing collected packages: shtab, msgspec, tyro, tokenizers, xformers, transformers, datasets, cut_cross_entropy, bitsandbytes, trl, peft, unsloth_zoo, unsloth\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.0\n","    Uninstalling tokenizers-0.22.0:\n","      Successfully uninstalled tokenizers-0.22.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.56.1\n","    Uninstalling transformers-4.56.1:\n","      Successfully uninstalled transformers-4.56.1\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.17.1\n","    Uninstalling peft-0.17.1:\n","      Successfully uninstalled peft-0.17.1\n","Successfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 msgspec-0.19.0 peft-0.17.0 shtab-1.7.2 tokenizers-0.21.4 transformers-4.55.2 trl-0.21.0 tyro-0.9.31 unsloth-2025.8.5 unsloth_zoo-2025.8.4 xformers-0.0.32.post2\n"]}]},{"cell_type":"code","source":["import torch\n","from unsloth import FastLanguageModel\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, DataCollatorForSeq2Seq\n","from datasets import Dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMLJH7GX_5pB","executionInfo":{"status":"ok","timestamp":1758058066372,"user_tz":-120,"elapsed":32966,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"6e455210-ba80-4bc2-d8ad-505495961db8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n"]}]},{"cell_type":"markdown","source":["### 2. 加载预训练模型和分词器 (Tokenizer)"],"metadata":{"id":"rrBE_J77B9s7"}},{"cell_type":"code","source":["# 定义模型和一些基本参数\n","max_seq_length = 8192\n","dtype = None # None 表示自动选择 (Float16 a T4, V100, BFloat16 a Ampere)\n","load_in_4bit = True # 使用 4bit 量化加载\n","\n","# 这是您的模型标识符，请替换为您正在使用的模型\n","# 例如：\"qwen-1.5b_lora_model\"\n","# model_name = \"qwen-1.5b_lora_model\"\n","# model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\"\n","model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit\"\n","\n","# 这一步会返回一个经过 Unsloth 优化的模型和一个分词器\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = model_name,\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["61457b7dbeba4083b5028a283fda2f77","c93c0395638b4d0d99b535ce60c6df21","31141f27b0d241ea8cfbac97a457a5d9","b0757b4804ad4f01b84cced7696f48b1","5950e8e0a3894f13acf289cbb3d6c29e","3a9119ea481f4c2ebd6fa2e84299265f","b48d8604b74d4302bcc1342cd27b094d","bcd0f3a7d5834880aca5152e0dfb068d","3615396e2ff943a48fcc1c1847f88a09","a5b3d7dd647647c0849f3fc45deb2073","3612ff9fbaeb4c9488157d01f1040019","b30827fc4fe94b0b8051e97c2e49d19b","d7c0754b99c34bf0a5ff02423fd9191f","a06ee37d994a4475aec90ad106ae82e1","00695dcaac1843a4ac6094992038fbd0","4a4b4ddbce2643fb9eae2dde5098df57","0975a098b24b48b8bdecebb6534a61e8","503a2a0815bd4db38b7c6342989afd12","fd3d14df741845febced56c271dd30c0","ba76767cc2364f9ea9d35511dfb791cf","ee9618ee5c804af59f3a51758fb2ffa0","7172d1eaa1af4d70ac6f9cd3594d04e6","420209a6c71e4640876e159efca8f313","69e9118867df4971b18e7deff9cb0d2b","cb45382a7c574c00a505f8d19972f4a5","641e40b82547425e8ead3898f0433751","273c3744058542838f15fef3d1bbd64f","4e0fb6b1f0a24588afab96abf23a7afe","c8746adc5c0246439d1ce9af112d2fd0","28d491f6976e4047ad204fcffa851378","08d73708977b46c793f67e17d8ba252d","3a5b1bc85f4c45bd9a322f6c1379adaf","7c8c8dbac0c64c5cb3ff252ace2329a7","2b2a1f84c0a7447bac8626fbb3f39a3f","8cc7383de124479e851c6096958951ac","e0293b229d37498e9b5f777f140b115a","b4d6f4254a5041ffa517ec0c80857a3e","d7ae72a271fe49028f988e3d7608e95d","df7a02efb0204c0a89a189365569327b","d55950dc82f74571b88fad328bb35d80","f4b6629a62014557944ea81e1952bebc","f45543c7aa91460ea17c2b80854207d2","4b2bdead0f2f44cc8b84ab8394bdc693","00e970ee94484549a518128f39070125","b897916e6f504460b0f7b57d79b95344","27fc571f3467433a928dc82bbd4a5d44","2d47a0cba0754496b94d921004e3bade","855c21fb9784413daebe9894e028affc","b860f806426443629c9db1ab127cf796","befd05dcbf7c44d49baf0be3829df511","5b1f2c957a8649ef954962eae65ecdf2","acd7f7e2849d4d38b188054552feeee4","fa8bdf232c874ea49d491c4be0b8bb23","676b3dfb2b2a486aba1eff95ab1c7536","5c76424449d4443da3dec203cab9a577"]},"id":"_pV0eUslAwYh","executionInfo":{"status":"ok","timestamp":1758058087583,"user_tz":-120,"elapsed":21208,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"fe04a70e-cedb-45b5-d072-50fa91bbdc50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.8.5: Fast Qwen2 patching. Transformers: 4.55.2.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.81G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61457b7dbeba4083b5028a283fda2f77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b30827fc4fe94b0b8051e97c2e49d19b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"420209a6c71e4640876e159efca8f313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2a1f84c0a7447bac8626fbb3f39a3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b897916e6f504460b0f7b57d79b95344"}},"metadata":{}}]},{"cell_type":"markdown","source":["### 3. 微调前推理测试\n","\n","在对模型进行任何修改之前，我们先用它来生成一段文本，看看原始模型的表现如何。这可以作为我们微调效果的基准参考。"],"metadata":{"id":"g4lhvCp8COB4"}},{"cell_type":"code","source":["# 模型推理的 Prompt 模板\n","inference_prompt = \"\"\"以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n","请撰写一份恰当的回复，以完成该请求。\n","在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n","\n","\n","### Instruction:\n","你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n","请回答以下医学问题。\n","\n","### Question:\n","{}\n","\n","### Response:\n","<think>{}\n","\"\"\""],"metadata":{"id":"Rvboqm1pAyJO","executionInfo":{"status":"ok","timestamp":1758058087593,"user_tz":-120,"elapsed":7,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model)\n","\n","question = \"男，28岁，程序员，最近一周每天工作到半夜，感觉头晕、脖子疼，有时候还恶心。\"\n","\n","inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n","attention_mask = inputs.input_ids.ne(tokenizer.pad_token_id).long().to(\"cuda\")\n","\n","outputs = model.generate(\n","    input_ids=inputs.input_ids,\n","    attention_mask=inputs.attention_mask,\n","    max_new_tokens=1200,\n","    use_cache=True,\n",")"],"metadata":{"id":"d60VEvDHBnVU","executionInfo":{"status":"ok","timestamp":1758058119834,"user_tz":-120,"elapsed":32239,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["response = tokenizer.batch_decode(outputs, skip_special_tokens=True)"],"metadata":{"id":"30c-RBs1BpBv","executionInfo":{"status":"ok","timestamp":1758058119839,"user_tz":-120,"elapsed":15,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(response[0].split(\"### Response:\")[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_ZiTCfKBqem","executionInfo":{"status":"ok","timestamp":1758058119857,"user_tz":-120,"elapsed":20,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"eb55b657-1c53-407c-9cd4-d3a454c3d542"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","<think>\n","好的，我来仔细分析一下这个问题。首先，用户是一名28岁的男性程序员，最近一周每天工作到半夜，感觉头晕、脖子疼，有时还恶心。这是一些常见的症状，需要结合临床推理、诊断学和治疗规划来综合分析。\n","\n","首先，头晕和脖子疼可能与神经系统的某些问题有关，比如脑力损伤、神经系统疾病或者运动神经损伤。同时，恶心也有可能是由于消化系统的问题，比如胃炎、食管炎或者胃食管反流病。不过，由于用户是程序员，可能有工作压力较大，导致这些症状。\n","\n","接下来，考虑可能的诊断因素。头晕和脖子疼可能与脑力损伤有关，如中风、脑力损伤综合征等。恶心可能与消化系统疾病相关，比如胃炎、食管炎或胃食管反流病。但考虑到用户是程序员，可能在工作压力下，这些症状可能不是由脑力损伤直接引起的，而是由长期的神经损伤或运动神经损伤导致的。\n","\n","另外，可能需要考虑是否存在神经系统疾病，如中风，或者运动神经损伤。由于用户是程序员，可能有脑力损伤，但需要进一步评估。此外，消化系统疾病如胃炎也可能需要排除。\n","\n","治疗方面，可能需要综合治疗，包括急性治疗（如药物治疗，如抗恶心药、抗抑郁药）和慢性治疗（如物理治疗，如平衡训练）。此外，心理治疗可能也是必要的，因为长期的工作压力可能会影响患者的神经功能。\n","\n","综合来看，可能的诊断包括中风、脑力损伤综合征、神经损伤（如运动神经损伤）或消化系统疾病。治疗方面，可能需要药物治疗、物理治疗和心理治疗。\n","</think>\n","\n","### 分步思考过程：\n","\n","1. **问题分析**：\n","   - 用户为男性，28岁，程序员，工作持续到半夜，导致头晕、脖子疼和恶心。\n","   - 问题涉及神经系统的常见症状，可能与神经损伤相关。\n","\n","2. **可能的诊断因素**：\n","   - **头晕和脖子疼**：可能是神经系统的损伤，如中风、脑力损伤或运动神经损伤。\n","   - **恶心**：可能与消化系统疾病（如胃炎、食管炎）或神经系统的其他问题相关。\n","\n","3. **临床推理**：\n","   - 程序员可能长期处于高压工作环境中，可能引发脑力损伤或运动神经损伤。\n","   - 潜在的神经损伤可能导致头晕、脖子疼和恶心。\n","\n","4. **诊断建议**：\n","   - **脑力损伤**：考虑中风、脑力损伤综合征等。\n","   - **神经损伤**：考虑运动神经损伤、脑部损伤或神经中枢问题。\n","   - **消化系统疾病**：考虑胃炎、食管炎或反流性胃炎。\n","\n","5. **治疗方案**：\n","   - **急性治疗**：药物治疗（如抗恶心药、抗抑郁药）。\n","   - **慢性治疗**：物理治疗（如平衡训练），心理治疗（如焦虑管理）。\n","\n","### 最终回复：\n","\n","该患者可能涉及脑力损伤或神经损伤，可能需要进一步的神经科或神经损伤科评估。建议建议患者尽快就医，进行全面的评估，以确定具体的诊断，并制定相应的治疗方案。\n"]}]},{"cell_type":"markdown","source":["---\n","\n","### 4. 下载和格式化训练数据集\n","\n","\n","医学推理数据集：https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/viewer/zh\n"],"metadata":{"id":"E2AehCn6CWbV"}},{"cell_type":"code","source":["# 模型训练的 Prompt 模板\n","train_prompt = \"\"\"以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n","请撰写一份恰当的回复，以完成该请求。\n","在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n","\n","\n","### Instruction:\n","你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n","请回答以下医学问题。\n","\n","### Question:\n","{}\n","\n","### Response:\n","<think>\n","{}\n","</think>\n","{}\n","\"\"\""],"metadata":{"id":"ggum-VTcBrkD","executionInfo":{"status":"ok","timestamp":1758058119862,"user_tz":-120,"elapsed":2,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["EOS_TOKEN = tokenizer.eos_token # 添加 EOS Token\n","\n","def formatting_prompts_func(examples):\n","    inputs = examples[\"Question\"]\n","    cots = examples[\"Complex_CoT\"]\n","    outputs = examples[\"Response\"]\n","    texts = []\n","    for input, cot, output in zip(inputs, cots, outputs):\n","        # 将 EOS Token 添加到样本最后\n","        text = train_prompt.format(input, cot, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"zh\", split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["2a1c55160ea9442e980947c3da07e715","36bc7625e00940fc806a0668683db47d","ded01950cac94f068642b397c630290f","18fb2efe53df47d48564e83b52ec3822","2a8bdde76bd54a3d83e099970be357bd","dd8d1b66da2b445db147f6e0ac87fba4","98aff273647e4e889fe888c425da93a1","2453867b134d480a8df46d028299ce7c","cf7897a39a4345f18170606418548bb4","82490cce89754262956b66dc9b570855","3d18fa835f9143ac8d860ecca1a2a0b7","7b90e1d9ce8646c4b84182d1e6e287b3","f061485042e44e8cacd9386d1eb51ca4","1b09dbfb32fb47f085f3366e89b17fea","7507d959839f458da755338750326d3f","ef4e0da22f0f4f5abf3a0c0e37e0cffa","ea405c52f991417e901dad4859bc3de0","36cfe0a881644c8b9b3bc4bc33c86f79","ceda78d656d24541a4e9222f55f243fa","4a2f3ef847da459aa2f8a9a25b30059c","3f35c2e41dd946db943eb007da7d7417","7e0c7db8b5de44a9957c382fa2966340","ec99310a8eef4b158bcfa3bd80915cc5","2bbb5f4736c54172ab01fa3e33c0d0dd","09773533f9e84b10867e08297106741a","06cc2c9fde74436896854b3d38db85d8","bba3b4da9a6f48daa8954365af8ada0b","e4b84a0847984f7aa9eb786e4b2d399c","2732ff12713e491d8d563a764a8821c9","386215cc3f554d01b84bd8927349d0cc","04a216a1c0a145f888f9327649d7bd4a","0ff6d5b619fd4e878641d5ac1ca6268a","0d2e3b1a994a4233b930ae60fc34f3c1","f489d4959fa54c1dbf48e4423cc16bce","c27f562d447848e388bf20819229f40d","769ddbfc8cc94a12b1f08aabfd0f76a3","3a053679eeb749318b55342f0423d710","424b0013c85649f1869a26b745679293","67c8ddf34a9f4fa39434065133d6e563","92fa2d23bc26434092275935cba0c700","a8b14857654c43798da82c9f43d4662b","ce2c77c62a794cdfb383ec6bad8cbced","5cd42715f3fa4ab68a611a5309501147","cca96914c1cd4d0d87dad236db99a53d"]},"id":"DkOwBoqCBvNa","executionInfo":{"status":"ok","timestamp":1758058184709,"user_tz":-120,"elapsed":64843,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"c0fb3e67-0112-4ad9-e17f-4aa31c2ba0ad"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a1c55160ea9442e980947c3da07e715"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["medical_o1_sft_Chinese.json:   0%|          | 0.00/50.6M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b90e1d9ce8646c4b84182d1e6e287b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/20171 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec99310a8eef4b158bcfa3bd80915cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20171 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f489d4959fa54c1dbf48e4423cc16bce"}},"metadata":{}}]},{"cell_type":"code","source":["dataset[0][\"text\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"8jWK-fChBwxg","executionInfo":{"status":"ok","timestamp":1758058184725,"user_tz":-120,"elapsed":12,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"1e191fd5-f757-4707-f838-5b1d99fcd936"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\\n请撰写一份恰当的回复，以完成该请求。\\n在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\\n\\n\\n### Instruction:\\n你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\\n请回答以下医学问题。\\n\\n### Question:\\n根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？\\n\\n### Response:\\n<think>\\n这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。\\n</think>\\n从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。\\n<｜end▁of▁sentence｜>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from IPython.display import display, Markdown\n","\n","display(Markdown(dataset[0][\"text\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":625},"id":"0nSlfgXPByI6","executionInfo":{"status":"ok","timestamp":1758058184767,"user_tz":-120,"elapsed":39,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"dc0ee800-c9fb-4905-a2a2-035fe1ee6775"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n请撰写一份恰当的回复，以完成该请求。\n在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n\n\n### Instruction:\n你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n请回答以下医学问题。\n\n### Question:\n根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？\n\n### Response:\n<think>\n这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\n\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\n\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\n\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\n\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\n\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\n\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\n\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\n\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\n\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。\n</think>\n从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。\n<｜end▁of▁sentence｜>"},"metadata":{}}]},{"cell_type":"markdown","source":["### 5. 使用 Unsloth 添加 LoRA 适配器\n","\n","这是使用 `unsloth` 的核心步骤。我们调用 `FastLanguageModel.get_peft_model`，它会非常高效地为模型注入 LoRA 模块。\n","\n","- `r`: LoRA 的秩 (rank)，是控制模型复杂度和参数量的关键超参数。\n","- `target_modules`: 指定要在哪些线性层（如注意力机制的 q, k, v, o 投影层）上应用 LoRA。\n","- `lora_alpha`: LoRA 的缩放因子，通常设置为 `r` 的两倍或与 `r` 相同。\n","- `use_gradient_checkpointing`: 一种节省显存的技术，对于训练大模型至关重要。"],"metadata":{"id":"xXYgLEjfCnO5"}},{"cell_type":"code","source":["# 因为 `model` 对象现在是由 Unsloth 创建的，它包含了所有必需的属性\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=16,\n","    target_modules=[\n","      \"q_proj\",\n","      \"k_proj\",\n","      \"v_proj\",\n","      \"o_proj\",\n","      \"gate_proj\",\n","      \"up_proj\",\n","      \"down_proj\",\n","    ],\n","    lora_alpha=16,\n","    lora_dropout=0,\n","    bias=\"none\",\n","    use_gradient_checkpointing=\"unsloth\",\n","    random_state=1432,\n","    use_rslora=False,\n","    loftq_config=None,\n",")\n","# 检查模型结构，确认 LoRA 适配器已添加\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lflRvDOdBzcL","executionInfo":{"status":"ok","timestamp":1758058191004,"user_tz":-120,"elapsed":6235,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"1ffa821c-e7e9-49ed-fce3-9564d44db878"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.8.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"]},{"output_type":"stream","name":"stdout","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Qwen2ForCausalLM(\n","      (model): Qwen2Model(\n","        (embed_tokens): Embedding(151936, 1536, padding_idx=151654)\n","        (layers): ModuleList(\n","          (0): Qwen2DecoderLayer(\n","            (self_attn): Qwen2Attention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8960, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","          )\n","          (1-2): 2 x Qwen2DecoderLayer(\n","            (self_attn): Qwen2Attention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8960, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","          )\n","          (3-25): 23 x Qwen2DecoderLayer(\n","            (self_attn): Qwen2Attention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8960, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","          )\n","          (26): Qwen2DecoderLayer(\n","            (self_attn): Qwen2Attention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8960, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","          )\n","          (27): Qwen2DecoderLayer(\n","            (self_attn): Qwen2Attention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=256, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1536, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8960, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8960, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1536, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["### 6. 配置 SFTTrainer\n","\n","`SFTTrainer` (Supervised Fine-tuning Trainer) 是一个专门用于指令微调的训练器。我们需要配置 `TrainingArguments` 来指定所有的训练参数，如批量大小、学习率、优化器等。"],"metadata":{"id":"7aMKALb8Crly"}},{"cell_type":"code","source":["from trl import SFTConfig, SFTTrainer\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = SFTConfig(\n","        per_device_train_batch_size = 64,\n","        gradient_accumulation_steps = 2,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 1432,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5111a27b342d48acbd2a86652ec6b537","5bbe6c809ec041f797f7da7328af2e47","1b9c320f787a4ff89f9809065555f256","8ee6457daa9e4c98b2968c2391ba6a6e","0027695c4a1447469edea33f5e74e227","3a9db902820b4b3d9f6497f9c9d19236","9160ac02519d42ff979fdabd00a61e09","bdae64e48c534bc392a39090192f615f","e1e5e8407c1f41f3946726ff3a381a32","7e7eb67c2e504ab196b8f65b6ffebdb4","0d9aa87a936447999b02f25ce17847f6"]},"id":"a3ltwL4_B4wY","executionInfo":{"status":"ok","timestamp":1758058209385,"user_tz":-120,"elapsed":18374,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"772db13c-f4a8-4d7d-8f03-3c60b6949225"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/20171 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5111a27b342d48acbd2a86652ec6b537"}},"metadata":{}}]},{"cell_type":"markdown","source":["### 7. 开始训练\n","\n","一切准备就绪后，调用 `trainer.train()` 即可开始微调过程。训练结束后，会返回包含训练统计信息（如训练损失）的对象。"],"metadata":{"id":"GCogzx-3DJvr"}},{"cell_type":"code","source":["trainer_stats = trainer.train()\n","\n","# 打印训练统计信息\n","print(trainer_stats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6kh_fTJNB8Nk","executionInfo":{"status":"ok","timestamp":1758058731842,"user_tz":-120,"elapsed":522446,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"23ebbc57-0db1-4009-aa9a-6d6a0bb357bf"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n","O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 2\n","\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 2 x 1) = 128\n"," \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 08:25, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.160600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.169000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.077400</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.165800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.149700</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.008400</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.984600</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.946500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.901200</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.794600</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.798000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.706200</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.696300</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.627600</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.666100</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.620000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.538800</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.532000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>2.465100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.465900</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.476900</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>2.421200</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.407900</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>2.376600</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>2.388500</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>2.346100</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.320300</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.340200</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>2.336200</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.331600</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.320000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.379000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>2.297600</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.302200</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.331300</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>2.288500</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>2.328300</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>2.324600</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>2.311200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.246700</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>2.297800</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>2.290600</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>2.276700</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>2.254200</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>2.270600</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>2.259500</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>2.288300</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>2.260200</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>2.308600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.280300</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>2.253300</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>2.308400</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>2.289400</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>2.241300</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>2.268300</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>2.299400</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>2.240700</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>2.243900</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>2.235500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.246900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TrainOutput(global_step=60, training_loss=2.4793787558873492, metrics={'train_runtime': 519.3894, 'train_samples_per_second': 14.787, 'train_steps_per_second': 0.116, 'total_flos': 7.163728311484416e+16, 'train_loss': 2.4793787558873492})\n"]}]},{"cell_type":"markdown","source":["### 8. 保存微调后的模型（Lora）\n","\n","训练完成后，您可以再次进行推理，比较微调后的模型与原始模型的差异。如果对结果满意，可以使用 `model.save_pretrained(\"your_lora_adapter_path\")` 来保存训练好的 LoRA 适配器。"],"metadata":{"id":"2uRFS5FoDOjh"}},{"cell_type":"code","source":["model.save_pretrained(\"qwen-1.5b_lora_model\")"],"metadata":{"id":"A978PYfZB_ay","executionInfo":{"status":"ok","timestamp":1758058732517,"user_tz":-120,"elapsed":668,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(\"qwen-1.5b_lora_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JKoN28SB_xc","executionInfo":{"status":"ok","timestamp":1758058732626,"user_tz":-120,"elapsed":86,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"bf644b4c-eea5-401b-d524-9c22aa35972c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('qwen-1.5b_lora_model/tokenizer_config.json',\n"," 'qwen-1.5b_lora_model/special_tokens_map.json',\n"," 'qwen-1.5b_lora_model/chat_template.jinja',\n"," 'qwen-1.5b_lora_model/tokenizer.json')"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### 9. 测试训练后的生成结果"],"metadata":{"id":"13sb2UIXDSKy"}},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","question=\"一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\", # Question\n","inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n","\n","outputs = model.generate(\n","    input_ids=inputs.input_ids,\n","    attention_mask=inputs.attention_mask,\n","    max_new_tokens=1000,\n","    use_cache=True,\n",")"],"metadata":{"id":"wN4DMUVDCA8Y","executionInfo":{"status":"ok","timestamp":1758058755169,"user_tz":-120,"elapsed":22536,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","print(output[0].split(\"### Response:\")[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XZUvdl4CCqF","executionInfo":{"status":"ok","timestamp":1758058755186,"user_tz":-120,"elapsed":9,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"75403706-22f1-4f4c-8d3f-8a43038a6c76"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","<think>\n","这位病人，5天已经得了急性阑尾炎，还有一点腹痛和发热，但还是有右下腹的压痛包块。这个压痛包块，看起来很严重，可能就是阑尾炎的典型表现。\n","\n","首先，这个压痛包块是阑尾炎的常见症状之一，它通常来自阑尾部的炎症反应，尤其是急性阶段。所以，根据这个情况，需要立即处理。\n","\n","急性阑尾炎的患者应该立即就医，因为症状已经很严重，这会带来严重的后果。因此，立即进行紧急处理是必要的。\n","\n","立即的紧急处理包括立即就医，这能帮助医生快速诊断和治疗。然而，患者在紧急情况下可能需要立即停止用药，尤其是抗生素，以避免进一步的感染。\n","\n","根据这个情况，患者应该立即停止抗生素治疗。这可能有助于减轻感染，防止进一步扩散。同时，观察压痛包块是否还有其他症状，比如疼痛或肿胀，如果症状没有改善，可能需要进一步的治疗。\n","\n","在紧急情况下，及时处理是非常重要的。因此，患者需要立即就医，并立即停止抗生素使用。\n","\n","综上所述，立即就医是治疗急性阑尾炎的必要步骤。患者应该立即停止抗生素，并观察症状，以便获得进一步的诊断和治疗。\n","</think>\n","根据患者的症状描述，急性阑尾炎的患者已经发病5天，腹痛稍有减轻但仍然发热，并且在体检时发现右下腹有压痛的包块。在这种情况下，立即的紧急处理是必要的。\n","\n","急性阑尾炎通常表现为压痛包块，这通常与阑尾炎的急性阶段有关。因此，患者需要立即就医以获得准确的诊断和治疗。\n","\n","为了防止进一步的感染，患者应该立即停止使用抗生素。由于压痛包块仍然存在，建议立即观察症状，以便获得进一步的诊断。\n","\n","因此，患者应立即就医，并立即停止抗生素治疗。这有助于减轻感染，并在进一步诊断和治疗中提供有效的治疗方案。\n","\n"]}]},{"cell_type":"code","source":["def generate_response(question: str, model, tokenizer, inference_prompt: str, max_new_tokens: int = 1024) -> str:\n","    \"\"\"\n","    使用指定的模型和分词器为给定的医学问题生成响应。\n","\n","    Args:\n","        question (str): 需要模型回答的医学问题。\n","        model: 已加载的 Unsloth/Hugging Face 模型。\n","        tokenizer: 对应的分词器。\n","        inference_prompt (str): 用于格式化输入的 f-string 模板。\n","        max_new_tokens (int, optional): 生成响应的最大 token 数量。默认为 1024。\n","\n","    Returns:\n","        str: 模型生成的响应文本，已去除 prompt 部分。\n","    \"\"\"\n","    # 1. 使用模板格式化输入\n","    prompt = inference_prompt.format(\n","        question, # 填充问题\n","        \"\",       # 留空，让模型生成 CoT 和 Response\n","    )\n","\n","    # 2. 将格式化后的 prompt 进行分词，并转移到 GPU\n","    inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","\n","    # 3. 使用模型生成输出\n","    # use_cache=True 用于加速解码过程\n","    outputs = model.generate(\n","        input_ids=inputs.input_ids,\n","        attention_mask=inputs.attention_mask,\n","        max_new_tokens=max_new_tokens,\n","        use_cache=True,\n","    )\n","\n","    # 4. 将生成的 token 解码为文本\n","    # skip_special_tokens=True 会移除像 EOS_TOKEN 这样的特殊标记\n","    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","\n","    # 5. 切分字符串，只返回 \"### Response:\" 之后的部分\n","    # 使用 .split() 分割并获取响应内容，.strip() 用于去除可能存在的前后空白字符\n","    response_part = decoded_output.split(\"### Response:\")\n","    if len(response_part) > 1:\n","        return response_part[1].strip()\n","    else:\n","        # 如果模型没有生成 \"### Response:\" 标记，则返回整个生成内容以供调试\n","        return decoded_output"],"metadata":{"id":"3Schhm3gCD74","executionInfo":{"status":"ok","timestamp":1758058755191,"user_tz":-120,"elapsed":2,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["my_question = \"对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？\"\n","\n","response = generate_response(my_question, model, tokenizer, inference_prompt)\n","print(\"==================== 模型回答 ====================\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9jKr0VtCFJp","executionInfo":{"status":"ok","timestamp":1758058790100,"user_tz":-120,"elapsed":34904,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"3df47f70-2ef3-4c0d-a7b9-db8c1848b24e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["==================== 模型回答 ====================\n","<think>\n","嗯，这位60岁的男患者，表现右侧胸痛，X线检查显示右侧肋膈角消失，这很像是肺结核的症状。那肺结核是怎么回事呢？我记得肺结核是肺部的结核病，通常会导致胸腔积液。所以，这个患者可能有肺结核。\n","\n","现在，问题来了，这位患者出现的是肺结核，对吗？所以，肺结核通常会导致肺部的结核病，导致胸腔积液。那问题是要找一个实验室检查，来了解这个胸腔积液的性质。\n","\n","嗯，首先，我想到了X线检查已经显示了肋膈角消失，所以这可能是一个肺结核的表现。那么，另一个可能性是，这个胸腔积液可能来自结核病。\n","\n","那么，接下来，我需要考虑一些可能的实验室检查，来看看哪种方法能帮助了解这个胸腔积液的性质。\n","\n","首先，血常规检查可以告诉我血浆蛋白的水平，这可以帮助了解是否有感染性或感染性变化，但其实，对于肺结核这种疾病，血常规可能对肺部的感染性表现不一定有直接帮助。\n","\n","然后是胸腔穿刺检查，这是常用的检查方法。它可以帮助我们了解胸腔的液体状态，比如是否有液体积液。但其实，对于肺结核，胸腔积液是由肺结核引起的，所以这可能能直接帮助我们了解这一点。\n","\n","再考虑一下尿常规，它可以帮助了解是否有尿液中的细菌或病毒，但这可能对肺结核的诊断没有直接的帮助，因为肺结核通常不会引起尿道感染。\n","\n","至于体格检查，比如呼吸系统检查，它可以帮助了解患者的呼吸状况，比如是否出现呼吸困难，这可能对于肺结核患者也有一定的帮助。\n","\n","然后是心肺功能检查，比如心肺电图，这可能有助于了解心肺功能，但这可能不是最直接的手段来了解胸腔积液。\n","\n","再想一下，胸腔穿刺检查，它确实可以帮助了解胸腔液体的状态，比如液体是否是液体性的还是气体性的。对于肺结核，肺部的液体可能来自肺泡，所以胸腔穿刺检查可以帮助我们了解这一点。\n","\n","嗯，所以，我想到，胸腔穿刺检查是了解肺腔液体状态的最佳方法。它能明确地告诉我们，这个胸腔液是液体性的还是气体性的，这对于肺结核的诊断和治疗都很重要。\n","\n","嗯，所以，综合来看，胸腔穿刺检查对了解胸腔积液的性质是有帮助的。\n","</think>\n","胸腔穿刺检查对于了解肺腔液体状态非常有用。肺结核通常是由于肺部感染导致的，而肺部的液体通常来自于肺泡，所以胸腔穿刺检查可以帮助明确知道这些液体是液体性的还是气体性的。这对于诊断和治疗肺结核患者至关重要，因为了解液体状态可以指导治疗措施，例如液体灌注或液体治疗。因此，胸腔穿刺检查是了解肺腔积液性质的最直接方法。\n"]}]},{"cell_type":"code","source":["my_question = \"对于一名 28 岁的男性患者，工作是程序员，常年熬夜，最近突然感觉头晕目眩，甚至有点恶心。请问有可能是什么疾病？\"\n","\n","response = generate_response(my_question, model, tokenizer, inference_prompt)\n","print(\"==================== 模型回答 ====================\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsR3w07XCNxj","executionInfo":{"status":"ok","timestamp":1758058831472,"user_tz":-120,"elapsed":41370,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"a13770f2-f419-4f7d-90b7-f5eb919cc6ea"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["==================== 模型回答 ====================\n","<think>\n","这个28岁的男性患者，工作是程序员，长期熬夜，最近突然头晕目眩，甚至有点恶心，这让我想到可能有高血压的问题。高血压的话，通常会有高血压引起的头晕目眩，尤其是夜间。不过，也有可能是其他原因造成的。再想想，这个患者工作很累，长期熬夜，可能还与睡眠不足有关。睡眠不足会导致头晕和恶心。还有一种可能性是糖尿病，糖尿病患者常常有头晕，尤其是夜间。不过，糖尿病患者需要特别注意饮食和运动，避免熬夜。\n","\n","然后，再看看高血压引起的晕眩，通常有高血压倾向。高血压患者往往会有头晕、恶心、头痛和口干舌燥等症状。这个患者有头晕和恶心，也有可能是高血压。不过，高血压患者还需要注意饮食和睡眠，避免熬夜。\n","\n","再想一下，这个患者长期熬夜，可能是因为长期的疲劳，导致睡眠不足。如果他有高血压，可能需要调整睡眠时间，但同时也要注意饮食和运动，避免熬夜。\n","\n","不过，也有可能他有糖尿病。糖尿病患者如果长期熬夜，可能会有头晕，但通常不会伴随恶心。不过，如果他有糖尿病，同时有高血压，可能需要特别注意饮食和运动，避免熬夜。\n","\n","再看看，这个患者的工作是程序员，长期熬夜，可能还有其他原因，比如脑力损伤导致的脑血管疾病，比如高血压或者糖尿病。或者，他可能有慢性肾病，因为长期的睡眠不足可能导致肾功能不佳。\n","\n","综合来看，最有可能的是高血压或者糖尿病。因为高血压和糖尿病都可能导致头晕目眩和恶心，同时，长期熬夜可能与睡眠不足有关。此外，糖尿病患者需要特别注意饮食和运动，避免熬夜。\n","\n","不过，也有可能是心脑血管疾病，比如心脑血管疾病，但这种情况下，患者通常会有心慌、呼吸困难和意识模糊，而不是头晕目眩和恶心。\n","\n","再想想，高血压患者需要考虑饮食和睡眠，避免熬夜。同时，糖尿病患者需要特别注意饮食和运动，避免熬夜。\n","\n","综合考虑，最有可能是高血压或糖尿病。因为这两种疾病通常与长期的睡眠不足有关，导致头晕目眩和恶心。而心脑血管疾病通常与心力衰竭有关，患者会有心慌等症状，而不是头晕目眩和恶心。\n","\n","再看下，患者工作是程序员，长期熬夜，这可能与脑力损伤有关，导致心力衰竭。心脑血管疾病包括高血压、糖尿病、肾病、心脏病等，这些疾病通常与心力衰竭有关，患者的头晕目眩和恶心可能与这些疾病有关。\n","\n","不过，还有一种可能是高血压和糖尿病同时存在，但需要特别注意饮食和运动，避免熬夜。因此，综合来看，最可能的疾病是高血压或糖尿病。\n","\n","再想一下，这个患者工作是程序员，长期熬夜，可能有脑力损伤，导致心力衰竭。因此，高血压和糖尿病可能更符合他的症状。\n","\n","不过，也有可能是高血压，因为长期熬夜可能导致睡眠不足，从而导致头晕目眩和恶心，这和高血压的常见表现一致。\n","\n","所以，综合来看，最有可能的是高血压，或者糖尿病。因为这两种疾病通常与长期的睡眠不足有关，导致头晕目眩和恶心。\n","</think>\n","根据患者的情况，一名28岁的男性患者工作是程序员，长期熬夜，突然头晕目眩甚至恶心，这提示可能有高血压或糖尿病的可能。高血压通常会导致头晕、恶心、头痛和口干舌燥，而糖尿病患者常常有头晕和恶心，尤其夜间。此外，长期的睡眠不足也可能导致这些症状。因此，最有可能的疾病是高血压或糖尿病。\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"54xM0D43CPZ7","executionInfo":{"status":"ok","timestamp":1758058831484,"user_tz":-120,"elapsed":27,"user":{"displayName":"Kun He","userId":"01086819182759852206"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LfKpofgEbGgg","executionInfo":{"status":"ok","timestamp":1758058866505,"user_tz":-120,"elapsed":34304,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"e42d04d6-12b7-4bcf-b27c-5119c9d705ca"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cd /content && zip -r qwen-1.5b_lora_model.zip qwen-1.5b_lora_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3q9esHqbGjV","executionInfo":{"status":"ok","timestamp":1758058871169,"user_tz":-120,"elapsed":4667,"user":{"displayName":"Kun He","userId":"01086819182759852206"}},"outputId":"a8d10169-545d-4d46-9066-03a7fe1d32db"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: qwen-1.5b_lora_model/ (stored 0%)\n","  adding: qwen-1.5b_lora_model/adapter_config.json (deflated 57%)\n","  adding: qwen-1.5b_lora_model/special_tokens_map.json (deflated 70%)\n","  adding: qwen-1.5b_lora_model/chat_template.jinja (deflated 75%)\n","  adding: qwen-1.5b_lora_model/tokenizer_config.json (deflated 88%)\n","  adding: qwen-1.5b_lora_model/tokenizer.json (deflated 81%)\n","  adding: qwen-1.5b_lora_model/README.md (deflated 65%)\n","  adding: qwen-1.5b_lora_model/adapter_model.safetensors (deflated 8%)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V3CqygflbGmK"},"execution_count":null,"outputs":[]}]}