# DeepSeek-R1医疗微调实验报告

## 核心发现 💡

**最重要的结论**: 几乎所有微调版本都比原版表现差，只有版本八(14B模型+超低学习率)接近原版水平。

**关键启示**: 对于已经优化的模型，错误的微调策略会导致性能严重下降。有时候不微调就是最好的微调。

## 实验概述

- **目标**: 测试DeepSeek-R1系列在医疗场景的微调效果
- **方法**: 8个版本对比(3个原版 + 5个微调版本)
- **数据**: 中文医疗推理数据集，约500条样本
- **技术**: LoRA微调 + 4bit量化

## 测试案例与心得

### 标准测试案例
我们用同一个医疗案例测试所有版本：
> "28岁程序员，常年熬夜，头晕目眩，恶心"

### 关键观察
1. **原版模型已经很强**: 14B原版在医疗推理上表现优秀
2. **微调容易"教坏"模型**: 大部分微调版本变得更差
3. **参数调优至关重要**: 版本八证明了正确微调的可能性
4. **模型规模很重要**: 14B比7B更抗微调损伤，1.5B最容易崩溃

## 技术配置

### 数据与模型
- **数据集**: FreedomIntelligence/medical-o1-reasoning-SFT (约500条中文医疗问答)
- **模型**: DeepSeek-R1系列 (1.5B/7B/14B)
- **方法**: LoRA微调 + 4bit量化

### 关键参数设置
- **LoRA配置**: r=16, lora_alpha=16
- **序列长度**: 8192 tokens
- **批次大小**: 64 (失败版本) / 调整后更小
- **学习率**: 2e-4 (失败版本) → 5e-6 (成功版本)
- **训练步数**: 60步 (失败版本) → 30步 (成功版本)

## 8版本对比结果

| 版本 | 模型 | 类型 | 微调参数 | 诊断准确性 | 推理质量 | 建议实用性 | 总体表现 |
|------|------|------|----------|------------|----------|------------|----------|
| 版本一 | DeepSeek-R1-1.5B | 微调 | lr=2e-4, steps=60 | 差 | 严重混乱 | 误导性 | **最差** |
| 版本二 | DeepSeek-R1-1.5B | 原版 | - | 中等 | 基础 | 一般 | 中等 |
| 版本三 | DeepSeek-R1-7B | 原版 | - | 良好 | 系统性 | 详细 | 良好 |
| 版本四 | DeepSeek-R1-14B | 原版 | - | 优秀 | 专业 | 全面实用 | **最佳** |
| 版本五 | DeepSeek-R1-7B | 微调 | lr=2e-4, steps=60 | 一般 | 基础 | 简单 | 基础 |
| 版本六 | DeepSeek-R1-14B | 微调 | lr=2e-4, steps=60 | 良好 | 清晰 | 基础 | 良好 |
| 版本七 | DeepSeek-R1-7B | 微调 | lr=3e-6, steps=30 | 中等偏下 | 过度复杂 | 宽泛 | 中等偏下 |
| 版本八 | DeepSeek-R1-14B | 微调 | lr=5e-6, steps=30 | 优秀 | 深入全面 | 系统实用 | 优秀 |

### 结果分析

**性能排名**: 版本四(14B原版) > 版本八(14B改进微调) > 版本六(14B微调) > 版本三(7B原版) > 版本七(7B改进微调) > 版本五(7B微调) ≈ 版本二(1.5B原版) > 版本一(1.5B微调)

**核心发现**:
1. **原版模型普遍优于微调版本**，除了版本八接近原版版本四的水平
2. **微调参数调整显示出改进趋势**：使用更低学习率和更少步数的版本七、八比早期微调版本表现更好
3. **大模型更抗微调损伤**：14B模型(版本六、八)相比7B模型(版本五、七)在微调后保持了更好的性能

**性能变化对比**:
- **1.5B模型**: 严重退化 (lr=2e-4 → 崩溃)
- **7B模型**:
  - 第一次微调(版本五): 明显退化 (lr=2e-4, steps=60)
  - 第二次微调(版本七): 轻微改善但仍低于原版 (lr=3e-6, steps=30)
- **14B模型**:
  - 第一次微调(版本六): 轻微退化 (lr=2e-4, steps=60)
  - 第二次微调(版本八): 接近原版水平 (lr=5e-6, steps=30)

## 重要发现：微调参数优化的成效

### 版本八的突破性表现

**版本八作为14B模型的改进微调版本，实现了接近原版水平的表现**，这证明了正确的微调策略是可行的：

**成功要素分析**：
1. **极低学习率** (5e-6)：避免了对预训练知识的破坏
2. **适中训练步数** (30步)：在学习新知识和避免过拟合间找到平衡
3. **频繁监控** (eval_steps=5)：允许及时发现和纠正训练偏差
4. **大模型优势**：14B参数提供了足够的容错空间

**版本八 vs 版本四的对比**：
- **医学准确性**：版本八几乎达到版本四(原版14B)的水平
- **推理深度**：版本八在某些方面甚至超越了原版
- **实用性**：版本八提供了更系统的解决方案

### 微调失败与成功的分水岭

**失败案例模式**：
- 版本一、五、六：高学习率(2e-4) + 长训练(60步) = 灾难性遗忘
- 版本七：虽然参数保守，但7B模型容量限制导致知识过度复杂化

**成功案例要素**：
- 版本八：超低学习率(5e-6) + 适中训练(30步) + 大模型(14B) = 接近原版水平

## 技术问题诊断

### 1. 灾难性遗忘 (Catastrophic Forgetting)
- **问题**: 微调过程中新任务学习覆盖了原有的医疗推理能力
- **表现**: 小模型(1.5B)遗忘最严重，大模型(14B)相对抗损
- **原因**: DeepSeek-R1本身就是推理优化模型，微调破坏了原有能力

### 2. 数据质量与规模差异
- **训练数据**: ~500条医疗问答样本
- **原始预训练**: 万亿token级别的高质量数据
- **质量对比**: 微调数据可能不如DeepSeek原始训练数据的质量

### 3. 超参数配置问题
- **学习率过高**: 2e-4可能对已经优化的模型过于激进
- **训练步数过多**: 60步可能导致过拟合
- **批次大小**: 64可能造成训练不稳定

### 4. 任务适配性问题
- **模型定位冲突**: DeepSeek-R1已经是医疗推理优化模型
- **微调目标错位**: 试图"教会"模型已经掌握的能力
- **能力窄化**: 专业化微调可能损害通用推理能力

### 训练过程问题
1. **Loss曲线异常**: 可能出现loss spike或过快收敛
2. **梯度爆炸**: 学习率过高导致参数更新过大
3. **过拟合**: 小数据集上训练过久

### 模型输出问题
1. **重复循环**: 1.5B微调版本出现token重复
2. **逻辑混乱**: 推理链条断裂，自相矛盾
3. **专业性下降**: 失去原有的医学术语准确性

## 经验教训

### 微调适用场景
**适合微调**:
- 基础模型能力不足时
- 任务与预训练差异很大时
- 有大量高质量标注数据时

**不适合微调**:
- 基础模型已经表现优秀时 ✓(本次情况)
- 微调数据质量不如预训练时 ✓(本次情况)
- 目标任务过于窄化时 ✓(本次情况)

### 核心启示
> **"好的基础模型 + 错误的微调 = 性能倒退"**
>
> **有时候不微调就是最好的微调**